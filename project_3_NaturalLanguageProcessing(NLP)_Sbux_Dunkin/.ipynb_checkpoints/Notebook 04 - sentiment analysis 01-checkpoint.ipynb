{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c93fe72-d917-4076-adb9-67dc22703c57",
   "metadata": {},
   "source": [
    "# Sentiment and Emotion Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a7eb51-769b-4076-bb69-fd48d4fe9354",
   "metadata": {},
   "source": [
    "Notebook 4 of 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1cc045-8c17-4b1d-a5c1-bfd2f87f77b1",
   "metadata": {},
   "source": [
    "We will analyse the post from each of the subreddits as well as some of the major topics from each to get understanding on the communities sentiment and emotion. In order to do so, we will utilise the Hugging Face pre-trained models for sentiment analysis as well as emotion analysis.\n",
    " \n",
    "The topics for each subreddit we will explore are:\n",
    "- Dunkin Donuts\n",
    " 1. dunkin donuts \n",
    " 2. pumpkin spice\n",
    " 3. cold brew \n",
    " 4. iced coffee \n",
    " 5. butter pecan\n",
    " 6. local dunkin\n",
    " 7. mobile order\n",
    " 8. drive thru\n",
    " 9. dunkin worker/ employee/ job\n",
    " \n",
    "- Starbucks\n",
    " 1. dress code \n",
    " 2. pumpkin spice\n",
    " 3. cold brew\n",
    " 4. iced coffee\n",
    " 5. apple crisp\n",
    " 6. fall launch\n",
    " 7. mobile order\n",
    " 8. drive thru\n",
    " 9. starbucks worker/ employee/ job\n",
    " \n",
    "Dunkin Donuts and Starbucks are the brands name? These follows by the top 3 most popular products for each subreddit based on the frequency of the words appear in the subreddit. The local and upcoming launch of product are also hot topics in both subreddits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e064b9ad-725e-463a-927e-718fae92f29e",
   "metadata": {},
   "source": [
    "## Import Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a604592e-2077-417f-8083-c3ea3e06f0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dea8d91-8dcc-410c-91f1-d33293837c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4997, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.read_csv('./datasets/combined_cleaned.csv')\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94c99b62-e1f1-47c7-9285-bdd771e27cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4997 entries, 0 to 4996\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Unnamed: 0      4997 non-null   int64 \n",
      " 1   subreddit       4997 non-null   int64 \n",
      " 2   selftext        3279 non-null   object\n",
      " 3   title           4997 non-null   object\n",
      " 4   created_utc     4997 non-null   int64 \n",
      " 5   title_selftext  4997 non-null   object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 234.4+ KB\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6f57d1e-093c-4014-a7d7-642dfd00c229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My coworker placing the hash browns like army ...</td>\n",
       "      <td>1663204910</td>\n",
       "      <td>my coworker placing the hash browns like army ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whats the deal with these?</td>\n",
       "      <td>1663196066</td>\n",
       "      <td>whats the deal with these? nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>I know I asked about this before but I'm just ...</td>\n",
       "      <td>Working for dunkin</td>\n",
       "      <td>1663193081</td>\n",
       "      <td>working for dunkin i know i asked about this b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subreddit                                           selftext  \\\n",
       "0           0          1                                                NaN   \n",
       "1           1          1                                                NaN   \n",
       "2           2          1  I know I asked about this before but I'm just ...   \n",
       "\n",
       "                                               title  created_utc  \\\n",
       "0  My coworker placing the hash browns like army ...   1663204910   \n",
       "1                         whats the deal with these?   1663196066   \n",
       "2                                 Working for dunkin   1663193081   \n",
       "\n",
       "                                      title_selftext  \n",
       "0  my coworker placing the hash browns like army ...  \n",
       "1                     whats the deal with these? nan  \n",
       "2  working for dunkin i know i asked about this b...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5155930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "combined_df = combined_df.drop(columns = ['Unnamed: 0', 'selftext', 'title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a529927a-8d1a-4c08-aa98-b8d82105559a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit         0\n",
       "created_utc       0\n",
       "title_selftext    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "combined_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7610a6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null\n",
    "combined_df = combined_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c38d54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit         0.0\n",
       "created_utc       0.0\n",
       "title_selftext    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for empty values\n",
    "combined_df[combined_df['title_selftext'] == ''].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6eb31b-316d-4c19-b4c4-2eaa51460e66",
   "metadata": {},
   "source": [
    "There is no missing values in dataset now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab464b8-8805-4178-82a9-0923a25b88ba",
   "metadata": {},
   "source": [
    "### Tokenize words and join back into a sentence to remove unwanted characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb0da46b-6056-477a-9968-a1d0958581fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac4b5e41-e867-4cd8-947d-a9f7a6731c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_selftext</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1663204910</td>\n",
       "      <td>my coworker placing the hash browns like army ...</td>\n",
       "      <td>[my, coworker, placing, the, hash, browns, lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1663196066</td>\n",
       "      <td>whats the deal with these? nan</td>\n",
       "      <td>[whats, the, deal, with, these, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1663193081</td>\n",
       "      <td>working for dunkin i know i asked about this b...</td>\n",
       "      <td>[working, for, dunkin, i, know, i, asked, abou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit  created_utc                                     title_selftext  \\\n",
       "0          1   1663204910  my coworker placing the hash browns like army ...   \n",
       "1          1   1663196066                     whats the deal with these? nan   \n",
       "2          1   1663193081  working for dunkin i know i asked about this b...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [my, coworker, placing, the, hash, browns, lik...  \n",
       "1               [whats, the, deal, with, these, nan]  \n",
       "2  [working, for, dunkin, i, know, i, asked, abou...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['tokenized'] = combined_df['title_selftext'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "combined_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8e3de39-b837-4611-b360-4c390745ee04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_selftext</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1663204910</td>\n",
       "      <td>my coworker placing the hash browns like army ...</td>\n",
       "      <td>[my, coworker, placing, the, hash, browns, lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1663196066</td>\n",
       "      <td>whats the deal with these nan</td>\n",
       "      <td>[whats, the, deal, with, these, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1663193081</td>\n",
       "      <td>working for dunkin i know i asked about this b...</td>\n",
       "      <td>[working, for, dunkin, i, know, i, asked, abou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit  created_utc                                     title_selftext  \\\n",
       "0          1   1663204910  my coworker placing the hash browns like army ...   \n",
       "1          1   1663196066                      whats the deal with these nan   \n",
       "2          1   1663193081  working for dunkin i know i asked about this b...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [my, coworker, placing, the, hash, browns, lik...  \n",
       "1               [whats, the, deal, with, these, nan]  \n",
       "2  [working, for, dunkin, i, know, i, asked, abou...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['title_selftext'] = combined_df['tokenized'].apply(lambda x: \" \".join(x))\n",
    "combined_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cead8e-7279-4e78-95a7-b272a084bb6c",
   "metadata": {},
   "source": [
    "### Separate into Starbucks and Dunkin Donuts datasets for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bea73e9-10f4-4ba9-90df-3fc3ab7cbd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2498, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddonuts_text_df = combined_df[combined_df['subreddit'] == 1]\n",
    "ddonuts_text_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efa6f4ff-3479-4a63-81d3-6c5a6ee14d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_selftext</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1663204910</td>\n",
       "      <td>my coworker placing the hash browns like army ...</td>\n",
       "      <td>[my, coworker, placing, the, hash, browns, lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1663196066</td>\n",
       "      <td>whats the deal with these nan</td>\n",
       "      <td>[whats, the, deal, with, these, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1663193081</td>\n",
       "      <td>working for dunkin i know i asked about this b...</td>\n",
       "      <td>[working, for, dunkin, i, know, i, asked, abou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit  created_utc                                     title_selftext  \\\n",
       "0          1   1663204910  my coworker placing the hash browns like army ...   \n",
       "1          1   1663196066                      whats the deal with these nan   \n",
       "2          1   1663193081  working for dunkin i know i asked about this b...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [my, coworker, placing, the, hash, browns, lik...  \n",
       "1               [whats, the, deal, with, these, nan]  \n",
       "2  [working, for, dunkin, i, know, i, asked, abou...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddonuts_text_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc09f3f7-96f7-4e59-b267-ed3a9724f9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2499, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbucks_text_df = combined_df[combined_df['subreddit'] == 0]\n",
    "sbucks_text_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88229c88-ec64-47cd-affb-129d07895db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_selftext</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>0</td>\n",
       "      <td>1663212467</td>\n",
       "      <td>interview tips hi all hopefully this question ...</td>\n",
       "      <td>[interview, tips, hi, all, hopefully, this, qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>0</td>\n",
       "      <td>1663212017</td>\n",
       "      <td>we had horses come through the drive thru rece...</td>\n",
       "      <td>[we, had, horses, come, through, the, drive, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>0</td>\n",
       "      <td>1663211903</td>\n",
       "      <td>having horses in the drive thru makes everythi...</td>\n",
       "      <td>[having, horses, in, the, drive, thru, makes, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit  created_utc  \\\n",
       "2498          0   1663212467   \n",
       "2499          0   1663212017   \n",
       "2500          0   1663211903   \n",
       "\n",
       "                                         title_selftext  \\\n",
       "2498  interview tips hi all hopefully this question ...   \n",
       "2499  we had horses come through the drive thru rece...   \n",
       "2500  having horses in the drive thru makes everythi...   \n",
       "\n",
       "                                              tokenized  \n",
       "2498  [interview, tips, hi, all, hopefully, this, qu...  \n",
       "2499  [we, had, horses, come, through, the, drive, t...  \n",
       "2500  [having, horses, in, the, drive, thru, makes, ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbucks_text_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e733be0-b04b-4b53-9884-3e3b6223e3b2",
   "metadata": {},
   "source": [
    "### Create separate dataframe for each of the subtopics for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa42c6f4-7e31-4ef2-adfa-070ac0524c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe of dunkin_donuts has shape (99, 4)\n",
      "Dataframe of dunkin_c_brew has shape (126, 4)\n",
      "Dataframe of dunkin_i_coffee has shape (13, 4)\n",
      "Dataframe of dunkin_b_pecan has shape (60, 4)\n",
      "Dataframe of dunkin_local has shape (77, 4)\n",
      "Dataframe of dunkin_reward has shape (96, 4)\n",
      "Dataframe of dunkin_service has shape (561, 4)\n",
      "Dataframe of dunkin_barista has shape (9, 4)\n"
     ]
    }
   ],
   "source": [
    "searchfor = ['dunkin donut', 'dunkin doughnut']\n",
    "dunkin_donuts = ddonuts_text_df[ddonuts_text_df['title_selftext'].str.contains('|'.join(searchfor))]\n",
    "dunkin_donuts = dunkin_donuts.copy()\n",
    "print(f'Dataframe of dunkin_donuts has shape {dunkin_donuts.shape}')\n",
    "dunkin_c_brew = ddonuts_text_df[ddonuts_text_df['title_selftext'].str.contains('cold brew')]\n",
    "dunkin_c_brew = dunkin_c_brew.copy()\n",
    "print(f'Dataframe of dunkin_c_brew has shape {dunkin_c_brew.shape}')\n",
    "dunkin_i_coffee = ddonuts_text_df[ddonuts_text_df['title_selftext'].str.contains('ice coff')]\n",
    "dunkin_i_coffee = dunkin_i_coffee.copy()\n",
    "print(f'Dataframe of dunkin_i_coffee has shape {dunkin_i_coffee.shape}')\n",
    "dunkin_b_pecan = ddonuts_text_df[ddonuts_text_df['title_selftext'].str.contains('butter pecan')]\n",
    "dunkin_b_pecan = dunkin_b_pecan.copy()\n",
    "print(f'Dataframe of dunkin_b_pecan has shape {dunkin_b_pecan.shape}')\n",
    "dunkin_local = ddonuts_text_df[ddonuts_text_df['title_selftext'].str.contains('local')]\n",
    "dunkin_local = dunkin_local.copy()\n",
    "print(f'Dataframe of dunkin_local has shape {dunkin_local.shape}')\n",
    "searchfor_1 = ['free drink', 'free bev', 'free beverag', 'rewards', 'reward']\n",
    "dunkin_reward = ddonuts_text_df[ddonuts_text_df['title_selftext'].str.contains('|'.join(searchfor_1))]\n",
    "dunkin_reward = dunkin_reward.copy()\n",
    "print(f'Dataframe of dunkin_reward has shape {dunkin_reward.shape}')\n",
    "searchfor_2 = ['mobile order', 'mobile orders', 'drive thru', 'drive through','app', 'workers', 'staff']\n",
    "dunkin_service = ddonuts_text_df[ddonuts_text_df['title_selftext'].str.contains('|'.join(searchfor_2))]\n",
    "dunkin_service = dunkin_service.copy()\n",
    "print(f'Dataframe of dunkin_service has shape {dunkin_service.shape}')\n",
    "searchfor_3 = ['barista', 'baristas']\n",
    "dunkin_barista = ddonuts_text_df[ddonuts_text_df['title_selftext'].str.contains('|'.join(searchfor_3))]\n",
    "dunkin_barista = dunkin_barista.copy()\n",
    "print(f'Dataframe of dunkin_barista has shape {dunkin_barista.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07149a7c-ba9d-44ea-a06a-e27943db34b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe of dunkin_donuts has shape (97, 4)\n",
      "Dataframe of dunkin_c_brew has shape (126, 4)\n",
      "Dataframe of dunkin_i_coffee has shape (13, 4)\n",
      "Dataframe of dunkin_b_pecan has shape (60, 4)\n",
      "Dataframe of dunkin_local has shape (77, 4)\n",
      "Dataframe of dunkin_reward has shape (96, 4)\n",
      "Dataframe of dunkin_service has shape (561, 4)\n",
      "Dataframe of dunkin_barista has shape (9, 4)\n"
     ]
    }
   ],
   "source": [
    "dunkin_donuts = ddonuts_text_df[ddonuts_text_df['title_selftext'].str.contains('dunkin donut')]\n",
    "dunkin_donuts = dunkin_donuts.copy()\n",
    "print(f'Dataframe of dunkin_donuts has shape {dunkin_donuts.shape}')\n",
    "dunkin_c_brew = ddonuts_text_df[ddonuts_text_df['title_selftext'].str.contains('cold brew')]\n",
    "dunkin_c_brew = dunkin_c_brew.copy()\n",
    "print(f'Dataframe of dunkin_c_brew has shape {dunkin_c_brew.shape}')\n",
    "dunkin_i_coffee = ddonuts_text_df[ddonuts_text_df['title_selftext'].str.contains('ice coff')]\n",
    "dunkin_i_coffee = dunkin_i_coffee.copy()\n",
    "print(f'Dataframe of dunkin_i_coffee has shape {dunkin_i_coffee.shape}')\n",
    "dunkin_b_pecan = ddonuts_text_df[ddonuts_text_df['title_selftext'].str.contains('butter pecan')]\n",
    "dunkin_b_pecan = dunkin_b_pecan.copy()\n",
    "print(f'Dataframe of dunkin_b_pecan has shape {dunkin_b_pecan.shape}')\n",
    "dunkin_local = ddonuts_text_df[ddonuts_text_df['title_selftext'].str.contains('local')]\n",
    "dunkin_local = dunkin_local.copy()\n",
    "print(f'Dataframe of dunkin_local has shape {dunkin_local.shape}')\n",
    "searchfor_1 = ['free drink', 'free bev', 'free beverag', 'rewards', 'reward']\n",
    "dunkin_reward = ddonuts_text_df[ddonuts_text_df['title_selftext'].str.contains('|'.join(searchfor_1))]\n",
    "dunkin_reward = dunkin_reward.copy()\n",
    "print(f'Dataframe of dunkin_reward has shape {dunkin_reward.shape}')\n",
    "searchfor_2 = ['mobile order', 'mobile orders', 'drive thru', 'drive through','app', 'workers', 'staff']\n",
    "dunkin_service = ddonuts_text_df[ddonuts_text_df['title_selftext'].str.contains('|'.join(searchfor_2))]\n",
    "dunkin_service = dunkin_service.copy()\n",
    "print(f'Dataframe of dunkin_service has shape {dunkin_service.shape}')\n",
    "searchfor_3 = ['barista', 'baristas']\n",
    "dunkin_barista = ddonuts_text_df[ddonuts_text_df['title_selftext'].str.contains('|'.join(searchfor_3))]\n",
    "dunkin_barista = dunkin_barista.copy()\n",
    "print(f'Dataframe of dunkin_barista has shape {dunkin_barista.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79e61c7e-ef34-4b50-bccc-129724a10f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe of sbucks_dress has shape (39, 4)\n",
      "Dataframe of sbucks_p_spice has shape (72, 4)\n",
      "Dataframe of sbucks_c_brew has shape (88, 4)\n",
      "Dataframe of dunkin_i_coffee has shape (6, 4)\n",
      "Dataframe of sbucks_a_crisp has shape (0, 4)\n",
      "Dataframe of sbucks_f_launch has shape (29, 4)\n",
      "Dataframe of sbucks_reward has shape (24, 4)\n",
      "Dataframe of sbucks_service has shape (673, 4)\n",
      "Dataframe of sbucks_barista has shape (335, 4)\n"
     ]
    }
   ],
   "source": [
    "sbucks_dress = sbucks_text_df[sbucks_text_df['title_selftext'].str.contains('dress code')]\n",
    "sbucks_dress = sbucks_dress.copy()\n",
    "print(f'Dataframe of sbucks_dress has shape {sbucks_dress.shape}')\n",
    "sbucks_p_spice = sbucks_text_df[sbucks_text_df['title_selftext'].str.contains('pumpkin spice')]\n",
    "sbucks_p_spice = sbucks_p_spice.copy()\n",
    "print(f'Dataframe of sbucks_p_spice has shape {sbucks_p_spice.shape}')\n",
    "sbucks_c_brew = sbucks_text_df[sbucks_text_df['title_selftext'].str.contains('cold brew')]\n",
    "sbucks_c_brew = sbucks_c_brew.copy()\n",
    "print(f'Dataframe of sbucks_c_brew has shape {sbucks_c_brew.shape}')\n",
    "sbucks_i_coffee = sbucks_text_df[sbucks_text_df['title_selftext'].str.contains('ice coff')]\n",
    "sbucks_i_coffee = sbucks_i_coffee.copy()\n",
    "print(f'Dataframe of dunkin_i_coffee has shape {sbucks_i_coffee.shape}')\n",
    "sbucks_a_crisp = sbucks_text_df[sbucks_text_df['title_selftext'].str.contains('appl crisp')]\n",
    "sbucks_a_crisp = sbucks_a_crisp.copy() \n",
    "print(f'Dataframe of sbucks_a_crisp has shape {sbucks_a_crisp.shape}')\n",
    "searchfor_4 = ['fall launch', 'fall drink', 'fall refresher', 'fall drinks']\n",
    "sbucks_f_launch = sbucks_text_df[sbucks_text_df['title_selftext'].str.contains('|'.join(searchfor_4))]\n",
    "sbucks_f_launch = sbucks_f_launch.copy()\n",
    "print(f'Dataframe of sbucks_f_launch has shape {sbucks_f_launch.shape}')\n",
    "searchfor_5 = ['free drink', 'free bev', 'free beverag', 'rewards', 'reward']\n",
    "sbucks_reward = sbucks_text_df[sbucks_text_df['title_selftext'].str.contains('|'.join(searchfor_1))]\n",
    "sbucks_reward = sbucks_reward.copy()\n",
    "print(f'Dataframe of sbucks_reward has shape {sbucks_reward.shape}')\n",
    "searchfor_6 = ['mobile order', 'mobile orders', 'drive thru', 'drive through', 'app', 'workers', 'staff']\n",
    "sbucks_service = sbucks_text_df[sbucks_text_df['title_selftext'].str.contains('|'.join(searchfor_6))]\n",
    "sbucks_service = sbucks_service.copy()\n",
    "print(f'Dataframe of sbucks_service has shape {sbucks_service.shape}')\n",
    "searchfor_7 = ['barista', 'baristas']\n",
    "sbucks_barista = sbucks_text_df[sbucks_text_df['title_selftext'].str.contains('|'.join(searchfor_7))]\n",
    "sbucks_barista = sbucks_barista.copy()\n",
    "print(f'Dataframe of sbucks_barista has shape {sbucks_barista.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650be658-6f85-493c-876c-65bec378990d",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81ab1a3-2cd0-4658-9148-7339fea7c95c",
   "metadata": {},
   "source": [
    "Model used: twitter-XLM-roBERTa-base for Sentiment Analysis. This model wastrained on about 124M tweets from Jan 2018 to Dec 2021, and finetuned for sentiment analysis with TweetEval benchmark. [source](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46e15d2a-83bb-418f-8eb7-2bfef5f75456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8fbb38d-37c0-4460-ad44-a2587048a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8e6188a-4426-4c7a-91ae-08de25cee411",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ce68ed6-8b94-452a-8052-59f619434daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_classifier = pipeline(\"sentiment-analysis\", \n",
    "                            model=model,\n",
    "                            tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e1accd9-9b34-4628-9b79-a96f2e759b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "806fff06-47ac-4de7-8144-f02a0171bf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500046474\n"
     ]
    }
   ],
   "source": [
    "p = pickle.dumps(senti_classifier)\n",
    "print(sys.getsizeof(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45971f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to extract sentiments\n",
    "def sentiments(dataset):\n",
    "    dataset['sentiment'] = dataset['title_selftext'].apply(senti_classifier)\n",
    "    dataset['sentiments'] = dataset['sentiment'].apply(lambda x: x[0]['label'])\n",
    "    dataset['sentiments'] = dataset['sentiments'].map({'LABEL_0': 'negative', 'LABEL_1': 'neutral', 'LABEL_2': 'positive'})\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5df26ad-d4f5-494d-a571-6bf7dbf9eb5f",
   "metadata": {},
   "source": [
    "## Dunkin Sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5622495c-b9f0-4e6d-b7f6-0041da10f618",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed735e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dunkin_sample_senti = sentiments(ddonuts_text_df.sample(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "429c12f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_selftext</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>1</td>\n",
       "      <td>1657716634</td>\n",
       "      <td>anyone know what the mixology stuff is appeare...</td>\n",
       "      <td>[anyone, know, what, the, mixology, stuff, is,...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.8710981607437...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1</td>\n",
       "      <td>1661398780</td>\n",
       "      <td>oatmilk or almondmilk psl are dunkin psl s mad...</td>\n",
       "      <td>[oatmilk, or, almondmilk, psl, are, dunkin, ps...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.8990364670753...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "      <td>1659987643</td>\n",
       "      <td>promo codes for new accounts i m starting my d...</td>\n",
       "      <td>[promo, codes, for, new, accounts, i, m, start...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.5711829662322...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit  created_utc  \\\n",
       "804          1   1657716634   \n",
       "240          1   1661398780   \n",
       "495          1   1659987643   \n",
       "\n",
       "                                        title_selftext  \\\n",
       "804  anyone know what the mixology stuff is appeare...   \n",
       "240  oatmilk or almondmilk psl are dunkin psl s mad...   \n",
       "495  promo codes for new accounts i m starting my d...   \n",
       "\n",
       "                                             tokenized  \\\n",
       "804  [anyone, know, what, the, mixology, stuff, is,...   \n",
       "240  [oatmilk, or, almondmilk, psl, are, dunkin, ps...   \n",
       "495  [promo, codes, for, new, accounts, i, m, start...   \n",
       "\n",
       "                                             sentiment sentiments  \n",
       "804  [{'label': 'LABEL_2', 'score': 0.8710981607437...   positive  \n",
       "240  [{'label': 'LABEL_1', 'score': 0.8990364670753...    neutral  \n",
       "495  [{'label': 'LABEL_2', 'score': 0.5711829662322...   positive  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunkin_sample_senti.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8416ddbf-4001-430a-8874-7ad3c12fa48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     253\n",
       "negative    166\n",
       "positive     81\n",
       "Name: sentiments, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunkin_sample_senti['sentiments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba20e89d-efc2-402f-a86e-abdbc23a403d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiments\n",
       "neutral          253\n",
       "negative         166\n",
       "positive          81"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunkin_sentiments = pd.DataFrame(dunkin_sample_senti['sentiments'].value_counts())\n",
    "dunkin_sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0caf85-4678-459b-ac42-3b684bee60a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dunkin Cold Brew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9685f1d0-73bf-4ac0-a08f-61ffac1a10a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dunkin_c_brew_senti = sentiments(dunkin_c_brew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf769537-974a-4618-8dfa-48963fc5816b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_selftext</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1663020154</td>\n",
       "      <td>3 md lattes my app advertises 3 med lattes and...</td>\n",
       "      <td>[3, md, lattes, my, app, advertises, 3, med, l...</td>\n",
       "      <td>[{'label': 'LABEL_0', 'score': 0.5559211373329...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>1662915853</td>\n",
       "      <td>this pumpkin cream cold brew is amazing weary_...</td>\n",
       "      <td>[this, pumpkin, cream, cold, brew, is, amazing...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.9879993200302...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>1662825134</td>\n",
       "      <td>anyone know what s the next coffee promo after...</td>\n",
       "      <td>[anyone, know, what, s, the, next, coffee, pro...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.9411011934280...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit  created_utc                                     title_selftext  \\\n",
       "22          1   1663020154  3 md lattes my app advertises 3 med lattes and...   \n",
       "41          1   1662915853  this pumpkin cream cold brew is amazing weary_...   \n",
       "52          1   1662825134  anyone know what s the next coffee promo after...   \n",
       "\n",
       "                                            tokenized  \\\n",
       "22  [3, md, lattes, my, app, advertises, 3, med, l...   \n",
       "41  [this, pumpkin, cream, cold, brew, is, amazing...   \n",
       "52  [anyone, know, what, s, the, next, coffee, pro...   \n",
       "\n",
       "                                            sentiment sentiments  \n",
       "22  [{'label': 'LABEL_0', 'score': 0.5559211373329...   negative  \n",
       "41  [{'label': 'LABEL_2', 'score': 0.9879993200302...   positive  \n",
       "52  [{'label': 'LABEL_1', 'score': 0.9411011934280...    neutral  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunkin_c_brew_senti.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40a66bf3-f705-4cca-9af6-f90c78dfeeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     57\n",
       "negative    41\n",
       "positive    28\n",
       "Name: sentiments, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunkin_c_brew_senti['sentiments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d84bb1a2-732b-4cb2-b5d3-2b41f6acceed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiments\n",
       "neutral           57\n",
       "negative          41\n",
       "positive          28"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunkin_c_brew_sentiments = pd.DataFrame(dunkin_c_brew_senti['sentiments'].value_counts())\n",
    "dunkin_c_brew_sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad38c4b3-ed26-4e7d-a8d4-4f0af369e816",
   "metadata": {},
   "source": [
    "### Dunkin Donuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37da78aa-98b1-4cda-8517-dd2b70d9ea16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (3123) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 3123].  Tensor sizes: [1, 514]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ddonuts_senti \u001b[38;5;241m=\u001b[39m \u001b[43msentiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdunkin_donuts\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36msentiments\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentiments\u001b[39m(dataset):\n\u001b[1;32m----> 3\u001b[0m     dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle_selftext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43msenti_classifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiments\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m     dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiments\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiments\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLABEL_0\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLABEL_1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLABEL_2\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:138\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:1067\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1067\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:1074\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1073\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1074\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1075\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1076\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:983\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m    982\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 983\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m    984\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:165\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[1;34m(self, model_inputs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_inputs):\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1206\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1204\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1217\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1218\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:814\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    813\u001b[0m     buffered_token_type_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mtoken_type_ids[:, :seq_length]\n\u001b[1;32m--> 814\u001b[0m     buffered_token_type_ids_expanded \u001b[38;5;241m=\u001b[39m \u001b[43mbuffered_token_type_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m buffered_token_type_ids_expanded\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (3123) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 3123].  Tensor sizes: [1, 514]"
     ]
    }
   ],
   "source": [
    "ddonuts_senti = sentiments(dunkin_donuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7a4cf20-9d5d-495f-9ee0-3d40a4257e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_selftext</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [subreddit, created_utc, title_selftext, tokenized, sentiment, sentiments]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddonuts_senti.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86c85542-689e-48c5-b596-3529e36f968c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     373\n",
       "negative     72\n",
       "positive     55\n",
       "Name: sentiments, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddonuts_senti['sentiments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50a65181-2fe8-4472-ade1-ddfdee2ca1a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiments\n",
       "neutral          373\n",
       "negative          72\n",
       "positive          55"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddonuts_sentiments = pd.DataFrame(ddonuts_senti['sentiments'].value_counts())\n",
    "ddonuts_sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6355c9-cd86-443e-a630-28c7529f6b07",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dunkin Iced Coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b4e136a-743e-492f-859f-b83251586172",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (653) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 653].  Tensor sizes: [1, 514]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dunkin_i_coffee_senti \u001b[38;5;241m=\u001b[39m \u001b[43msentiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdunkin_i_coffee\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36msentiments\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentiments\u001b[39m(dataset):\n\u001b[1;32m----> 3\u001b[0m     dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle_selftext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43msenti_classifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiments\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m     dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiments\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiments\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLABEL_0\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLABEL_1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLABEL_2\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:138\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:1067\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1067\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:1074\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1073\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1074\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1075\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1076\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:983\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m    982\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 983\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m    984\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:165\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[1;34m(self, model_inputs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_inputs):\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1206\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1204\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1217\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1218\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:814\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    813\u001b[0m     buffered_token_type_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mtoken_type_ids[:, :seq_length]\n\u001b[1;32m--> 814\u001b[0m     buffered_token_type_ids_expanded \u001b[38;5;241m=\u001b[39m \u001b[43mbuffered_token_type_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m buffered_token_type_ids_expanded\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (653) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 653].  Tensor sizes: [1, 514]"
     ]
    }
   ],
   "source": [
    "dunkin_i_coffee_senti = sentiments(dunkin_i_coffee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9c2dc7e-3fda-4069-b6b7-d053268f8ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_selftext</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1663190691</td>\n",
       "      <td>make ice tea order door dash tast ice tea orde...</td>\n",
       "      <td>[make, ice, tea, order, door, dash, tast, ice,...</td>\n",
       "      <td>[{'label': 'LABEL_0', 'score': 0.6549773812294...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>1662659909</td>\n",
       "      <td>blueberri crumbl ice coffe dunkin yesterday he...</td>\n",
       "      <td>[blueberri, crumbl, ice, coffe, dunkin, yester...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.8312905430793...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>1662652584</td>\n",
       "      <td>nutti pumpkin ice coffe good ive get ice coffe...</td>\n",
       "      <td>[nutti, pumpkin, ice, coffe, good, ive, get, i...</td>\n",
       "      <td>[{'label': 'LABEL_0', 'score': 0.4688285291194...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit  created_utc                                     title_selftext  \\\n",
       "3           1   1663190691  make ice tea order door dash tast ice tea orde...   \n",
       "68          1   1662659909  blueberri crumbl ice coffe dunkin yesterday he...   \n",
       "69          1   1662652584  nutti pumpkin ice coffe good ive get ice coffe...   \n",
       "\n",
       "                                            tokenized  \\\n",
       "3   [make, ice, tea, order, door, dash, tast, ice,...   \n",
       "68  [blueberri, crumbl, ice, coffe, dunkin, yester...   \n",
       "69  [nutti, pumpkin, ice, coffe, good, ive, get, i...   \n",
       "\n",
       "                                            sentiment sentiments  \n",
       "3   [{'label': 'LABEL_0', 'score': 0.6549773812294...   negative  \n",
       "68  [{'label': 'LABEL_1', 'score': 0.8312905430793...    neutral  \n",
       "69  [{'label': 'LABEL_0', 'score': 0.4688285291194...   negative  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunkin_i_coffee_senti.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "503ecaad-c522-4526-9939-3cb99ad92e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     133\n",
       "positive     29\n",
       "negative     27\n",
       "Name: sentiments, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunkin_i_coffee_senti['sentiments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1d169a4-49c7-4619-a273-10ef99007169",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiments\n",
       "neutral          133\n",
       "positive          29\n",
       "negative          27"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunkin_i_coffee_sentiments = pd.DataFrame(dunkin_i_coffee_senti['sentiments'].value_counts())\n",
    "dunkin_i_coffee_sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70e6320-3a91-4b61-8209-b9c20455b315",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dunkin Butter Pecan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9eca2ebb-c076-4cf4-aa22-84015a66c7cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (653) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 653].  Tensor sizes: [1, 514]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dunkin_b_pecan_senti \u001b[38;5;241m=\u001b[39m \u001b[43msentiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdunkin_b_pecan\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36msentiments\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentiments\u001b[39m(dataset):\n\u001b[1;32m----> 3\u001b[0m     dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle_selftext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43msenti_classifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiments\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m     dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiments\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiments\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLABEL_0\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLABEL_1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLABEL_2\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:138\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:1067\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1067\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:1074\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1073\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1074\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1075\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1076\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:983\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m    982\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 983\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m    984\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:165\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[1;34m(self, model_inputs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_inputs):\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1206\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1204\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1217\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1218\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:814\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    813\u001b[0m     buffered_token_type_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mtoken_type_ids[:, :seq_length]\n\u001b[1;32m--> 814\u001b[0m     buffered_token_type_ids_expanded \u001b[38;5;241m=\u001b[39m \u001b[43mbuffered_token_type_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m buffered_token_type_ids_expanded\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (653) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 653].  Tensor sizes: [1, 514]"
     ]
    }
   ],
   "source": [
    "dunkin_b_pecan_senti = sentiments(dunkin_b_pecan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9501555-ac5a-4f51-945f-95ff5b994ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_selftext</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1663022152</td>\n",
       "      <td>discontinu flavor swirl took call morn ladi sa...</td>\n",
       "      <td>[discontinu, flavor, swirl, took, call, morn, ...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.5559210181236...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>1662652584</td>\n",
       "      <td>nutti pumpkin ice coffe good ive get ice coffe...</td>\n",
       "      <td>[nutti, pumpkin, ice, coffe, good, ive, get, i...</td>\n",
       "      <td>[{'label': 'LABEL_0', 'score': 0.4688285291194...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1</td>\n",
       "      <td>1661538738</td>\n",
       "      <td>tf lemonad season work dunkin also go frequent...</td>\n",
       "      <td>[tf, lemonad, season, work, dunkin, also, go, ...</td>\n",
       "      <td>[{'label': 'LABEL_0', 'score': 0.5790102481842...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit  created_utc  \\\n",
       "20           1   1663022152   \n",
       "69           1   1662652584   \n",
       "221          1   1661538738   \n",
       "\n",
       "                                        title_selftext  \\\n",
       "20   discontinu flavor swirl took call morn ladi sa...   \n",
       "69   nutti pumpkin ice coffe good ive get ice coffe...   \n",
       "221  tf lemonad season work dunkin also go frequent...   \n",
       "\n",
       "                                             tokenized  \\\n",
       "20   [discontinu, flavor, swirl, took, call, morn, ...   \n",
       "69   [nutti, pumpkin, ice, coffe, good, ive, get, i...   \n",
       "221  [tf, lemonad, season, work, dunkin, also, go, ...   \n",
       "\n",
       "                                             sentiment sentiments  \n",
       "20   [{'label': 'LABEL_1', 'score': 0.5559210181236...    neutral  \n",
       "69   [{'label': 'LABEL_0', 'score': 0.4688285291194...   negative  \n",
       "221  [{'label': 'LABEL_0', 'score': 0.5790102481842...   negative  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunkin_b_pecan_senti.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36c645a4-6708-4a57-bf35-6763831db0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     39\n",
       "positive    12\n",
       "negative     8\n",
       "Name: sentiments, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunkin_b_pecan_senti['sentiments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86cc5bbd-08a6-422b-a3fb-501935674104",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiments\n",
       "neutral           39\n",
       "positive          12\n",
       "negative           8"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunkin_b_pecan_sentiments = pd.DataFrame(dunkin_b_pecan_senti['sentiments'].value_counts())\n",
    "dunkin_b_pecan_sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28edd08c-aeaf-40bd-a633-6f70407da3a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Dunkin Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "748e1d0f-e175-4bb6-8600-798804d444b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_selftext</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>1662958423</td>\n",
       "      <td>someon explain local dunkin dougnut longer ser...</td>\n",
       "      <td>[someon, explain, local, dunkin, dougnut, long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>1662306477</td>\n",
       "      <td>soup like dunkinrunsony survey free donut alwa...</td>\n",
       "      <td>[soup, like, dunkinrunsony, survey, free, donu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1</td>\n",
       "      <td>1662028911</td>\n",
       "      <td>tip return local dunkin morn hand girl tip usu...</td>\n",
       "      <td>[tip, return, local, dunkin, morn, hand, girl,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1</td>\n",
       "      <td>1661954305</td>\n",
       "      <td>don t know say someth went local dunkin that g...</td>\n",
       "      <td>[don, t, know, say, someth, went, local, dunki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1</td>\n",
       "      <td>1661953274</td>\n",
       "      <td>drive person window get keep tip new ladi work...</td>\n",
       "      <td>[drive, person, window, get, keep, tip, new, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit  created_utc  \\\n",
       "34           1   1662958423   \n",
       "104          1   1662306477   \n",
       "145          1   1662028911   \n",
       "158          1   1661954305   \n",
       "159          1   1661953274   \n",
       "\n",
       "                                        title_selftext  \\\n",
       "34   someon explain local dunkin dougnut longer ser...   \n",
       "104  soup like dunkinrunsony survey free donut alwa...   \n",
       "145  tip return local dunkin morn hand girl tip usu...   \n",
       "158  don t know say someth went local dunkin that g...   \n",
       "159  drive person window get keep tip new ladi work...   \n",
       "\n",
       "                                             tokenized  \n",
       "34   [someon, explain, local, dunkin, dougnut, long...  \n",
       "104  [soup, like, dunkinrunsony, survey, free, donu...  \n",
       "145  [tip, return, local, dunkin, morn, hand, girl,...  \n",
       "158  [don, t, know, say, someth, went, local, dunki...  \n",
       "159  [drive, person, window, get, keep, tip, new, l...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunkin_local.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "552bb3b3-7bd8-4756-adfb-5773f6e0d139",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dunkin_local_senti = sentiments(dunkin_local.sample(21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "76bcd3ae-d73a-449c-a534-3b799bbed976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_selftext</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>1</td>\n",
       "      <td>1655534248</td>\n",
       "      <td>im predict right one next drink matcha lemonad...</td>\n",
       "      <td>[im, predict, right, one, next, drink, matcha,...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.6368399262428...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1</td>\n",
       "      <td>1651601528</td>\n",
       "      <td>scream humili today b nice dunki employe ladi ...</td>\n",
       "      <td>[scream, humili, today, b, nice, dunki, employ...</td>\n",
       "      <td>[{'label': 'LABEL_0', 'score': 0.6598921418190...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2339</th>\n",
       "      <td>1</td>\n",
       "      <td>1645035383</td>\n",
       "      <td>muffin dont exactli go muffin wonder mayb some...</td>\n",
       "      <td>[muffin, dont, exactli, go, muffin, wonder, ma...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.5718753337860...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit  created_utc  \\\n",
       "1113          1   1655534248   \n",
       "1597          1   1651601528   \n",
       "2339          1   1645035383   \n",
       "\n",
       "                                         title_selftext  \\\n",
       "1113  im predict right one next drink matcha lemonad...   \n",
       "1597  scream humili today b nice dunki employe ladi ...   \n",
       "2339  muffin dont exactli go muffin wonder mayb some...   \n",
       "\n",
       "                                              tokenized  \\\n",
       "1113  [im, predict, right, one, next, drink, matcha,...   \n",
       "1597  [scream, humili, today, b, nice, dunki, employ...   \n",
       "2339  [muffin, dont, exactli, go, muffin, wonder, ma...   \n",
       "\n",
       "                                              sentiment sentiments  \n",
       "1113  [{'label': 'LABEL_1', 'score': 0.6368399262428...    neutral  \n",
       "1597  [{'label': 'LABEL_0', 'score': 0.6598921418190...   negative  \n",
       "2339  [{'label': 'LABEL_1', 'score': 0.5718753337860...    neutral  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunkin_local_senti.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4372eda5-6cbd-4e17-8c99-dcb219d8d822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     15\n",
       "negative     4\n",
       "positive     2\n",
       "Name: sentiments, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunkin_local_senti['sentiments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "71b915c6-3dc6-4276-9415-004315850f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiments\n",
       "neutral           15\n",
       "negative           4\n",
       "positive           2"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunkin_local_sentiments = pd.DataFrame(dunkin_local_senti['sentiments'].value_counts())\n",
    "dunkin_local_sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0499da-7431-43b5-aa16-47865005c298",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabb3d53-6819-4c73-a0c3-8222b44de8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dunkin_cols = [\"Overall\", \"Dunkin_Donuts\", \"Cold_Brew\", \"Iced_Coffee\", \"Butter_Pecan\", \"Dunkin_Local\"]\n",
    "dunkin_sentiments = pd.concat([ps5_sentiments, psplus_sentiments, pselden_sentiments, horizon_sentiments, ff_sentiments, pscont_sentiments], axis=1, ignore_index=True)\n",
    "playstation_sentiments.columns = ps_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ae408-3ec1-4e7c-977d-79f1ccf2b742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed13c73-675a-4c01-9149-d28080930693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b713cefd-2fa5-4e2d-b4eb-62b0c88a66ba",
   "metadata": {},
   "source": [
    "Remarks:\n",
    "- most posts are neutral, most likely are questions and discussions over the topics\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb4994b-3118-4cec-8ce6-7d7b181ed9c6",
   "metadata": {},
   "source": [
    "## Starbucks Sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b17c070-b36c-4839-89f6-6f83bb36464e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d09ae6b7-480a-4846-84f1-6dee69866d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbucks_sample_senti = sentiments(sbucks_text_df.sample(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e61b1d2e-7a42-432a-ba14-d7005759cce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_selftext</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>0</td>\n",
       "      <td>1662992585</td>\n",
       "      <td>lid dont stay ceram cup nan</td>\n",
       "      <td>[lid, dont, stay, ceram, cup, nan]</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.7076201438903...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4733</th>\n",
       "      <td>0</td>\n",
       "      <td>1661453752</td>\n",
       "      <td>question reshaken espresso vs latt sbux insid ...</td>\n",
       "      <td>[question, reshaken, espresso, vs, latt, sbux,...</td>\n",
       "      <td>[{'label': 'LABEL_0', 'score': 0.5602721571922...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4933</th>\n",
       "      <td>0</td>\n",
       "      <td>1661254898</td>\n",
       "      <td>starbuck dish sanit anyon els secur major dryn...</td>\n",
       "      <td>[starbuck, dish, sanit, anyon, els, secur, maj...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.5626117587089...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit  created_utc  \\\n",
       "2771          0   1662992585   \n",
       "4733          0   1661453752   \n",
       "4933          0   1661254898   \n",
       "\n",
       "                                         title_selftext  \\\n",
       "2771                        lid dont stay ceram cup nan   \n",
       "4733  question reshaken espresso vs latt sbux insid ...   \n",
       "4933  starbuck dish sanit anyon els secur major dryn...   \n",
       "\n",
       "                                              tokenized  \\\n",
       "2771                 [lid, dont, stay, ceram, cup, nan]   \n",
       "4733  [question, reshaken, espresso, vs, latt, sbux,...   \n",
       "4933  [starbuck, dish, sanit, anyon, els, secur, maj...   \n",
       "\n",
       "                                              sentiment sentiments  \n",
       "2771  [{'label': 'LABEL_1', 'score': 0.7076201438903...    neutral  \n",
       "4733  [{'label': 'LABEL_0', 'score': 0.5602721571922...   negative  \n",
       "4933  [{'label': 'LABEL_1', 'score': 0.5626117587089...    neutral  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbucks_sample_senti.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "40f31364-68c9-4fdb-af20-697b193458fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     394\n",
       "negative     63\n",
       "positive     43\n",
       "Name: sentiments, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbucks_sample_senti['sentiments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad1be5a3-c88b-40bc-9cd3-81e78f9cc57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiments\n",
       "neutral          394\n",
       "negative          63\n",
       "positive          43"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbucks_sentiments = pd.DataFrame(sbucks_sample_senti['sentiments'].value_counts())\n",
    "sbucks_sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef347bf2-74d0-4b13-9cd2-b2ac02a0c685",
   "metadata": {},
   "source": [
    "### Dress Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cb673d31-da59-4ab3-a8e5-00f1f85bd2a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sbucks_dress_senti = sentiments(sbucks_dress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7bede1d3-1a48-47fb-982d-5fe3f50a8a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_selftext</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>0</td>\n",
       "      <td>1663017656</td>\n",
       "      <td>dress code question realli cute black combat b...</td>\n",
       "      <td>[dress, code, question, realli, cute, black, c...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.8963563442230...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>0</td>\n",
       "      <td>1662882825</td>\n",
       "      <td>still wear flat cap starbuck also plaintshirt ...</td>\n",
       "      <td>[still, wear, flat, cap, starbuck, also, plain...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.8445830941200...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>0</td>\n",
       "      <td>1662808730</td>\n",
       "      <td>new hire bring first day train given list docu...</td>\n",
       "      <td>[new, hire, bring, first, day, train, given, l...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.7134898900985...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit  created_utc  \\\n",
       "2740          0   1663017656   \n",
       "2871          0   1662882825   \n",
       "2960          0   1662808730   \n",
       "\n",
       "                                         title_selftext  \\\n",
       "2740  dress code question realli cute black combat b...   \n",
       "2871  still wear flat cap starbuck also plaintshirt ...   \n",
       "2960  new hire bring first day train given list docu...   \n",
       "\n",
       "                                              tokenized  \\\n",
       "2740  [dress, code, question, realli, cute, black, c...   \n",
       "2871  [still, wear, flat, cap, starbuck, also, plain...   \n",
       "2960  [new, hire, bring, first, day, train, given, l...   \n",
       "\n",
       "                                              sentiment sentiments  \n",
       "2740  [{'label': 'LABEL_1', 'score': 0.8963563442230...    neutral  \n",
       "2871  [{'label': 'LABEL_1', 'score': 0.8445830941200...    neutral  \n",
       "2960  [{'label': 'LABEL_2', 'score': 0.7134898900985...   positive  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbucks_dress_senti.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "54f3feeb-6c8d-40d5-954c-fd45fc1b4ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     30\n",
       "positive     5\n",
       "negative     4\n",
       "Name: sentiments, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbucks_dress_senti['sentiments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae4c7977-0042-435c-8a43-602ee2e3796f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiments\n",
       "neutral           30\n",
       "positive           5\n",
       "negative           4"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbucks_dress_sentiments = pd.DataFrame(sbucks_dress_senti['sentiments'].value_counts())\n",
    "sbucks_dress_sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401314f1-b556-4899-b642-62ff2fdd7491",
   "metadata": {},
   "source": [
    "### Pumpkin Spice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1ca40d22-57e1-4244-a691-2646ae9f067c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sbucks_p_spice_senti = sentiments(sbucks_p_spice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec70bb70-faf1-4587-90bc-b8fa664119d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_selftext</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>0</td>\n",
       "      <td>1663109346</td>\n",
       "      <td>happi pumpkin spice season jackolantern nan</td>\n",
       "      <td>[happi, pumpkin, spice, season, jackolantern, ...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.8681311607360...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>0</td>\n",
       "      <td>1663047373</td>\n",
       "      <td>kj correct know syrup heap calori kj pumpkin s...</td>\n",
       "      <td>[kj, correct, know, syrup, heap, calori, kj, p...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.8142969608306...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>0</td>\n",
       "      <td>1662929371</td>\n",
       "      <td>allerg someth fall flavor what syrup i v three...</td>\n",
       "      <td>[allerg, someth, fall, flavor, what, syrup, i,...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.8318116068840...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit  created_utc  \\\n",
       "2636          0   1663109346   \n",
       "2698          0   1663047373   \n",
       "2832          0   1662929371   \n",
       "\n",
       "                                         title_selftext  \\\n",
       "2636        happi pumpkin spice season jackolantern nan   \n",
       "2698  kj correct know syrup heap calori kj pumpkin s...   \n",
       "2832  allerg someth fall flavor what syrup i v three...   \n",
       "\n",
       "                                              tokenized  \\\n",
       "2636  [happi, pumpkin, spice, season, jackolantern, ...   \n",
       "2698  [kj, correct, know, syrup, heap, calori, kj, p...   \n",
       "2832  [allerg, someth, fall, flavor, what, syrup, i,...   \n",
       "\n",
       "                                              sentiment sentiments  \n",
       "2636  [{'label': 'LABEL_1', 'score': 0.8681311607360...    neutral  \n",
       "2698  [{'label': 'LABEL_1', 'score': 0.8142969608306...    neutral  \n",
       "2832  [{'label': 'LABEL_1', 'score': 0.8318116068840...    neutral  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbucks_p_spice_senti.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0d0d6d10-970b-412a-9671-62af261130f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     55\n",
       "positive    12\n",
       "negative     5\n",
       "Name: sentiments, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbucks_p_spice_senti['sentiments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0892cdab-71b2-4f08-97c7-89b559a4acbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiments\n",
       "neutral           55\n",
       "positive          12\n",
       "negative           5"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbucks_p_spice_sentiments = pd.DataFrame(sbucks_p_spice_senti['sentiments'].value_counts())\n",
    "sbucks_p_spice_sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace46c04-2a38-46f3-a209-29bb1b54ada5",
   "metadata": {},
   "source": [
    "### Cold Brew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "61d6df0f-e4ca-4fa0-a696-b113b12a9f44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1034) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 1034].  Tensor sizes: [1, 514]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sbucks_c_brew_senti \u001b[38;5;241m=\u001b[39m \u001b[43msentiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43msbucks_c_brew\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36msentiments\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentiments\u001b[39m(dataset):\n\u001b[1;32m----> 3\u001b[0m     dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle_selftext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43msenti_classifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiments\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m     dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiments\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiments\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLABEL_0\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLABEL_1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLABEL_2\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:138\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:1067\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1067\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:1074\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1073\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1074\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1075\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1076\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:983\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m    982\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 983\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m    984\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:165\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[1;34m(self, model_inputs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_inputs):\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1206\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1204\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1217\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1218\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:814\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    813\u001b[0m     buffered_token_type_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mtoken_type_ids[:, :seq_length]\n\u001b[1;32m--> 814\u001b[0m     buffered_token_type_ids_expanded \u001b[38;5;241m=\u001b[39m \u001b[43mbuffered_token_type_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m buffered_token_type_ids_expanded\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (1034) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 1034].  Tensor sizes: [1, 514]"
     ]
    }
   ],
   "source": [
    "sbucks_c_brew_senti = sentiments(sbucks_c_brew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fd0e8cdc-1943-42a2-9e22-6224686178c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_selftext</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>0</td>\n",
       "      <td>1663017656</td>\n",
       "      <td>dress code question realli cute black combat b...</td>\n",
       "      <td>[dress, code, question, realli, cute, black, c...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.8963563442230...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>0</td>\n",
       "      <td>1662882825</td>\n",
       "      <td>still wear flat cap starbuck also plaintshirt ...</td>\n",
       "      <td>[still, wear, flat, cap, starbuck, also, plain...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.8445830941200...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>0</td>\n",
       "      <td>1662808730</td>\n",
       "      <td>new hire bring first day train given list docu...</td>\n",
       "      <td>[new, hire, bring, first, day, train, given, l...</td>\n",
       "      <td>[{'label': 'LABEL_2', 'score': 0.7134898900985...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit  created_utc  \\\n",
       "2740          0   1663017656   \n",
       "2871          0   1662882825   \n",
       "2960          0   1662808730   \n",
       "\n",
       "                                         title_selftext  \\\n",
       "2740  dress code question realli cute black combat b...   \n",
       "2871  still wear flat cap starbuck also plaintshirt ...   \n",
       "2960  new hire bring first day train given list docu...   \n",
       "\n",
       "                                              tokenized  \\\n",
       "2740  [dress, code, question, realli, cute, black, c...   \n",
       "2871  [still, wear, flat, cap, starbuck, also, plain...   \n",
       "2960  [new, hire, bring, first, day, train, given, l...   \n",
       "\n",
       "                                              sentiment sentiments  \n",
       "2740  [{'label': 'LABEL_1', 'score': 0.8963563442230...    neutral  \n",
       "2871  [{'label': 'LABEL_1', 'score': 0.8445830941200...    neutral  \n",
       "2960  [{'label': 'LABEL_2', 'score': 0.7134898900985...   positive  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbucks_c_brew_senti.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b9c452f-71ce-4044-a7ca-afed76731004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     30\n",
       "positive     5\n",
       "negative     4\n",
       "Name: sentiments, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbucks_dress_senti['sentiments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf766220-ac42-4804-a7e3-93d0b2460380",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiments\n",
       "neutral           30\n",
       "positive           5\n",
       "negative           4"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbucks_dress_sentiments = pd.DataFrame(sbucks_dress_senti['sentiments'].value_counts())\n",
    "sbucks_dress_sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef0073e-ae63-4a4e-a12c-1d8cbbf14c4f",
   "metadata": {},
   "source": [
    "### Apple Crisp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d4083956-e0df-43cf-850e-23c4e531bc0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sbucks_a_crisp_senti = sentiments(sbucks_a_crisp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50c9a3ce-fd59-4263-b9f7-64422190be88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_selftext</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>0</td>\n",
       "      <td>1663095901</td>\n",
       "      <td>ok i m curiou what correl someon like cilantro...</td>\n",
       "      <td>[ok, i, m, curiou, what, correl, someon, like,...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.8949554562568...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681</th>\n",
       "      <td>0</td>\n",
       "      <td>1663070793</td>\n",
       "      <td>typic went starbuck morn decid go insid drive ...</td>\n",
       "      <td>[typic, went, starbuck, morn, decid, go, insid...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.7545986175537...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>0</td>\n",
       "      <td>1663031317</td>\n",
       "      <td>appl crisp tast like straight chemic loudlycry...</td>\n",
       "      <td>[appl, crisp, tast, like, straight, chemic, lo...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.5060799121856...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit  created_utc  \\\n",
       "2657          0   1663095901   \n",
       "2681          0   1663070793   \n",
       "2720          0   1663031317   \n",
       "\n",
       "                                         title_selftext  \\\n",
       "2657  ok i m curiou what correl someon like cilantro...   \n",
       "2681  typic went starbuck morn decid go insid drive ...   \n",
       "2720  appl crisp tast like straight chemic loudlycry...   \n",
       "\n",
       "                                              tokenized  \\\n",
       "2657  [ok, i, m, curiou, what, correl, someon, like,...   \n",
       "2681  [typic, went, starbuck, morn, decid, go, insid...   \n",
       "2720  [appl, crisp, tast, like, straight, chemic, lo...   \n",
       "\n",
       "                                              sentiment sentiments  \n",
       "2657  [{'label': 'LABEL_1', 'score': 0.8949554562568...    neutral  \n",
       "2681  [{'label': 'LABEL_1', 'score': 0.7545986175537...    neutral  \n",
       "2720  [{'label': 'LABEL_1', 'score': 0.5060799121856...    neutral  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbucks_a_crisp_senti.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6092a3a8-14db-4162-84a6-e261aa8a1275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     21\n",
       "positive     5\n",
       "negative     3\n",
       "Name: sentiments, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbucks_a_crisp_senti['sentiments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d58c368d-d150-475b-9194-a4b1b90c4c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiments\n",
       "neutral           21\n",
       "positive           5\n",
       "negative           3"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbucks_a_crisp_sentiments = pd.DataFrame(sbucks_a_crisp_senti['sentiments'].value_counts())\n",
    "sbucks_a_crisp_sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25b93ca-4ba5-45ca-99f0-3847b1046676",
   "metadata": {},
   "source": [
    "### Fall Launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1cec7679-426a-4964-bc4a-643470aa55bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sbucks_f_launch_senti = sentiments(sbucks_f_launch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e7c29164-9917-4440-9a29-fe1457b3a3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_selftext</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3502</th>\n",
       "      <td>0</td>\n",
       "      <td>1662343518</td>\n",
       "      <td>board fall launch nan</td>\n",
       "      <td>[board, fall, launch, nan]</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.8202300071716...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>0</td>\n",
       "      <td>1662263514</td>\n",
       "      <td>fall launch sign ft duolingo cake pop nan</td>\n",
       "      <td>[fall, launch, sign, ft, duolingo, cake, pop, ...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.8723303079605...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>0</td>\n",
       "      <td>1662241595</td>\n",
       "      <td>swear last year fall launch didnt hit hard lik...</td>\n",
       "      <td>[swear, last, year, fall, launch, didnt, hit, ...</td>\n",
       "      <td>[{'label': 'LABEL_1', 'score': 0.5231901407241...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit  created_utc  \\\n",
       "3502          0   1662343518   \n",
       "3612          0   1662263514   \n",
       "3653          0   1662241595   \n",
       "\n",
       "                                         title_selftext  \\\n",
       "3502                              board fall launch nan   \n",
       "3612          fall launch sign ft duolingo cake pop nan   \n",
       "3653  swear last year fall launch didnt hit hard lik...   \n",
       "\n",
       "                                              tokenized  \\\n",
       "3502                         [board, fall, launch, nan]   \n",
       "3612  [fall, launch, sign, ft, duolingo, cake, pop, ...   \n",
       "3653  [swear, last, year, fall, launch, didnt, hit, ...   \n",
       "\n",
       "                                              sentiment sentiments  \n",
       "3502  [{'label': 'LABEL_1', 'score': 0.8202300071716...    neutral  \n",
       "3612  [{'label': 'LABEL_1', 'score': 0.8723303079605...    neutral  \n",
       "3653  [{'label': 'LABEL_1', 'score': 0.5231901407241...    neutral  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbucks_f_launch_senti.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "490de3ab-5002-4d26-9307-9a583fdfe134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     17\n",
       "positive     3\n",
       "Name: sentiments, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbucks_f_launch_senti['sentiments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f3fd1abb-983c-40b7-a8bc-9314ae5fa665",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiments\n",
       "neutral           17\n",
       "positive           3"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbucks_f_launch_sentiments = pd.DataFrame(sbucks_f_launch_senti['sentiments'].value_counts())\n",
    "sbucks_f_launch_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7709eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40be0bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a85ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b515df6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86176947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b1396f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f957e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918df860-5336-45fa-a68b-2018efaa48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --ignore-installed --upgrade tensorflow-gpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c29592dfe26c3b69cf4809b17a35da08b0c469cf0923c77f8f51a7709655b5af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
