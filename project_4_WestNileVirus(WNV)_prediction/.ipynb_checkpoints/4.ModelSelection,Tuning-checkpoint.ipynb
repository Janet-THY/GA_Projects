{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-6984d6d4-91a0-44b2-b048-48ab8a8cd84b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Project 4: West Nile Virus Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook 4 of 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-893ceef9-5aa5-4591-92f7-81ad9646f971",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "# Model Selection and Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-f44935ba-c522-455a-a213-43703a997865",
    "deepnote_cell_type": "code",
    "execution_millis": 1333,
    "execution_start": 1608128608763,
    "output_cleared": false,
    "source_hash": "af124294",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, RocCurveDisplay, roc_auc_score, \n",
    "accuracy_score, precision_score, recall_score, f1_score, auc, precision_recall_curve, average_precision_score, ConfusionMatrixDisplay, plot_roc_curve)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00002-d26f34ad-6abf-496c-be16-6ab0359fd630",
    "deepnote_cell_type": "code",
    "execution_millis": 621,
    "execution_start": 1608128610099,
    "output_cleared": false,
    "source_hash": "61892ba9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "train = pd.read_csv('./datasets/cleaned_train.csv')\n",
    "test = pd.read_csv('./datasets/cleaned_test.csv')\n",
    "weather = pd.read_csv('./datasets/cleaned_weather.csv')\n",
    "final_train = pd.read_csv('./datasets/final_train.csv')\n",
    "final_test = pd.read_csv('./datasets/final_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00003-bed317f1-f212-4037-9db2-4b05e7a8d655",
    "deepnote_cell_type": "code",
    "execution_millis": 1,
    "execution_start": 1608128610724,
    "output_cleared": false,
    "source_hash": "4a78b638"
   },
   "outputs": [],
   "source": [
    "test_id = test['Id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-a941914e-1263-4249-bff1-3ce3fe0eecd2",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "In this section, we tested out a variety of predictive models including a Logistic Regression classifier and tree-based algorithms like AdaBoost. We carried out the following process:\n",
    "- Train-test-split data\n",
    "- Calculated baseline and benchmark models\n",
    "- Fit model to training dataset\n",
    "- Ran models on our data without using any over- or under-sampling techniques to benchmark performance\n",
    "- Used the <b>Synthetic Minority Oversampling Technique (SMOTE)</b> to address the class imbalance within our target variable\n",
    "- Carried out hyper-parameter tuning on our most promising models \n",
    "- Identified our top performing model based on ROC-AUC score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-0234e2ec-67c9-4f2a-b02d-8f0dde8abead",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-916daf6c-8a21-4987-8382-94b10255b7b9",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Ultimately, we opted to drop these features. Dropping `year` has to no change in performance (we have `YearWeek` instead), and our other three polynomial features didn't give us significant increase in model AUC to justify the decreased interpretability of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00006-abeb98bf-0e31-4753-b231-d6db04154107",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "final_train = final_train.drop(columns=['Year', 'Sunrise_WeekAvgTemp', 'Sunrise_Tmin', 'Sunrise_WetBulb'])\n",
    "final_test = final_test.drop(columns=['Year', 'Sunrise_WeekAvgTemp', 'Sunrise_Tmin', 'Sunrise_WetBulb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train.shape, final_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00007-274a7688-659a-4c9f-9df0-fd58d6d02f47",
    "deepnote_cell_type": "code",
    "execution_millis": 7,
    "execution_start": 1608128610728,
    "output_cleared": false,
    "source_hash": "d926bca6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = final_train\n",
    "y = train['WnvPresent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-9ca5ec6f-a7e6-4e43-a585-0241f4faaf4e",
    "deepnote_cell_type": "code",
    "execution_millis": 7,
    "execution_start": 1608128610736,
    "output_cleared": false,
    "source_hash": "83720fbc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-ede1d761-5e72-4173-acf6-c13cc8db8e5e",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-d2601640-baf1-46fa-884c-80668199c7c9",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "The class imbalance within our target variable highlights the issue of using accuracy or R<sup>2</sup> as a metric for our model. The training dataset is strongly biased towards samples where WNV is absent. This means that simply classifying every data point as absent of WNV would <b>net our model accuracy of almost 94.6%</b>. \n",
    "\n",
    "In this scenario, we need another metric to help us avoid overfitting to a single class. Using Area Under Curve (AUC) is a great alternative, as it focuses on the sensitivity (TPR) and specificity (TNR) of our model. To elaborate, AUC measures how true positive rate (recall) and false positive rate trade-off. This reveals how good a model is at distinguishing between a positive class and a negative class.\n",
    "\n",
    "Using an AUC Reciever Operating Characteristic or AUC-ROC curve, <b>we can visually compare the true positive and false positive rates at a range of different classification thresholds to identify our best model</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00011-0c819aa6-ed3f-4803-af6b-8ebf6971caf8",
    "deepnote_cell_type": "code",
    "execution_millis": 9,
    "execution_start": 1608128610745,
    "output_cleared": false,
    "source_hash": "f64f4527",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Baseline\n",
    "y = train['WnvPresent']\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set y\n",
    "y_pred = 0\n",
    "y_train_baseline = np.array([y_pred] * y_train.shape[0])\n",
    "y_test_baseline = np.array([y_pred] * y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate metrics - accuracy, roc auc scores\n",
    "print('---Train Set---')\n",
    "print('Baseline Train Accuracy Score: {}'.format(accuracy_score(y_train, y_train_baseline)))\n",
    "print('Baseline Train ROC AUC Score: {}'.format(roc_auc_score(y_train, y_train_baseline)))\n",
    "print('\\n')\n",
    "print('---Test Set---')\n",
    "print('Baseline Test Accuracy Score: {}'.format(accuracy_score(y_test, y_test_baseline)))\n",
    "print('Baseline Test ROC AUC Score: {}'.format(roc_auc_score(y_test, y_test_baseline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00012-5a0a9055-101e-49bf-afbb-ea5002810c06",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "### Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00013-7f2d90e8-99e1-42ea-8bd8-78c4e011b595",
    "deepnote_cell_type": "code",
    "execution_millis": 0,
    "execution_start": 1608128610799,
    "output_cleared": false,
    "source_hash": "459d783d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instiantiate models\n",
    "models = {'lr': LogisticRegression(max_iter=5_000, random_state=42, solver='saga'),\n",
    "          'rf': RandomForestClassifier(random_state=42),\n",
    "          'gb': GradientBoostingClassifier(random_state=42),\n",
    "          'dt': DecisionTreeClassifier(random_state=42),\n",
    "          'et': ExtraTreesClassifier(random_state=42),\n",
    "          'ada': AdaBoostClassifier(random_state=42),\n",
    "          'svc': SVC(random_state=42, probability=True),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00014-de0f8222-f535-416c-8625-6108d47cb9c6",
    "deepnote_cell_type": "code",
    "execution_millis": 0,
    "execution_start": 1608128610799,
    "output_cleared": false,
    "source_hash": "3f14ae6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate lists to store results\n",
    "init_list = []\n",
    "gs_list = []\n",
    "\n",
    "# Function to run model -- input scaler and model\n",
    "def run_model(mod, mod_params={}, grid_search=False):\n",
    "    \n",
    "    # Initial dictionary to hold model results\n",
    "    results = {}\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "            ('ss', StandardScaler()),\n",
    "            (mod, models[mod])\n",
    "            ])\n",
    "    \n",
    "    if grid_search:\n",
    "        # Instantiate list to store gridsearch results\n",
    "        gs = GridSearchCV(pipe, param_grid=mod_params, cv=3, verbose=1, scoring='roc_auc', n_jobs=-1)\n",
    "        gs.fit(X_train, y_train)\n",
    "        pipe = gs\n",
    "        \n",
    "    else:\n",
    "        pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # Retrieve metrics\n",
    "    predictions = pipe.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "    y_test_pred_prob = pipe.predict_proba(X_test)[:,1]\n",
    "    y_train_pred_prob = pipe.predict_proba(X_train)[:,1]\n",
    "    \n",
    "    results['model'] = mod\n",
    "    results['train_auc'] = roc_auc_score(y_train, y_train_pred_prob)\n",
    "    results['test_auc'] = roc_auc_score(y_test, y_test_pred_prob)        \n",
    "    results['crossval_score'] = cross_val_score(models[mod], X_train, y_train, scoring='roc_auc', cv=3).mean()\n",
    "    results['precision'] = precision_score(y_test, predictions)\n",
    "    results['specificity'] = tn / (tn + fp)\n",
    "    results['recall'] = recall_score(y_test, predictions)\n",
    "    results['f_score'] = f1_score(y_test, predictions)\n",
    "    \n",
    "    if grid_search:\n",
    "        gs_list.append(results)\n",
    "        print('### BEST PARAMS ###')\n",
    "        display(pipe.best_params_)\n",
    "        \n",
    "    else:\n",
    "        init_list.append(results)\n",
    "    \n",
    "    print('### METRICS ###')\n",
    "    display(results)\n",
    "    \n",
    "    print(f\"True Negatives: {tn}\")\n",
    "    print(f\"False Positives: {fp}\")\n",
    "    print(f\"False Negatives: {fn}\")\n",
    "    print(f\"True Positives: {tp}\")\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-08bd86fc-0ed7-42c2-97e4-9d552886b61e",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "## Model Benchmarks \n",
    "In the beginning, we simply ran our models with no class adjustments and no hyper-parameter tuning. It's worth noting that <b>without feature engineering, our models performed substantially worse.</b> In iterations without feature engineering our Logistic Regression and AdaBoosting classifiers completely failed to identify any true positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00016-4e1a16da-ad47-454c-af81-998fd74e7fe3",
    "deepnote_cell_type": "code",
    "execution_millis": 1499,
    "execution_start": 1608128610800,
    "output_cleared": false,
    "source_hash": "59b0e4e3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = run_model('lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00017-4c68fee2-0c0f-4208-b181-c1ac693d6cfa",
    "deepnote_cell_type": "code",
    "execution_millis": 147,
    "execution_start": 1608128612301,
    "output_cleared": false,
    "source_hash": "4802dd4b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dt = run_model('dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00018-f4aed3d3-8181-4df2-aef4-447d27fde952",
    "deepnote_cell_type": "code",
    "execution_millis": 840,
    "execution_start": 1608128612452,
    "output_cleared": false,
    "source_hash": "4833c18",
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf = run_model('rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00019-d68064a6-6af7-41bb-b451-1e2a34c174e4",
    "deepnote_cell_type": "code",
    "execution_millis": 1703,
    "execution_start": 1608128613298,
    "output_cleared": false,
    "source_hash": "b512759b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "gb = run_model('gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00020-4d45ad24-40d3-4723-931f-19d7a5544e31",
    "deepnote_cell_type": "code",
    "execution_millis": 783,
    "execution_start": 1608128615005,
    "output_cleared": false,
    "source_hash": "46cc3bbc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "et = run_model('et')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00021-62d043d4-3a8f-444f-aef9-4f8c7154c84e",
    "deepnote_cell_type": "code",
    "execution_millis": 5965,
    "execution_start": 1608128615796,
    "output_cleared": false,
    "source_hash": "e20581f3"
   },
   "outputs": [],
   "source": [
    "svc = run_model('svc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00022-4c7e9030-1d14-4a15-b945-6019fc4bc964",
    "deepnote_cell_type": "code",
    "execution_millis": 545,
    "execution_start": 1608128621810,
    "output_cleared": false,
    "source_hash": "65028a56"
   },
   "outputs": [],
   "source": [
    "ada = run_model('ada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00023-894b2777-6fc4-4671-8899-3d728fb3cbbd",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "At this point, it's a bit hard to conclude which is the best classification model. Our Gradient Boosting classfier has the best test AUC scores, but it scores poorly in terms of sensitivity (a.k.a. recall), suggesting that the model isn't good at identifying true positives (i.e. mosquito pools where WNV is present).\n",
    "\n",
    "Conversely, some of our non-boosting tree classifiers have higher f-scores and are better at predicting true positives, but score poorly in terms of test AUC. This means that our positive and negative populations are overlapping to some degree. This means our model isn't good at predicting WNV - this is also reflected by the high number of positive and negative misclassifications (e.g. our decision tree classifier has the highest number of misclassifications - 99 false positives and 104 false negatives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics result of initial modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00024-4b47a211-f5fc-4083-bb9c-b337dd223fb4",
    "deepnote_cell_type": "code",
    "execution_millis": 25,
    "execution_start": 1608128622359,
    "output_cleared": false,
    "source_hash": "cb71c960",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Results of our initial modelling\n",
    "pd.DataFrame(init_list).sort_values(by='test_auc', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00025-78a4df15-2eb7-4ae2-a3da-821bc766e466",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "### AUC-ROC Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00026-d0c6fb3a-9ae4-4fec-ab1f-7615f0db511b",
    "deepnote_cell_type": "code",
    "execution_millis": 0,
    "execution_start": 1608128622387,
    "output_cleared": false,
    "source_hash": "4209889e"
   },
   "outputs": [],
   "source": [
    "init_dict = {\n",
    "    lr: 'LogisticRegression',\n",
    "    gb: 'GradientBoostingClassifier',\n",
    "    ada: 'AdaBoostClassifier',\n",
    "    rf: 'RandomForest',\n",
    "    svc: 'SupportVectorMachineCl',\n",
    "    # et: 'ExtraTrees',\n",
    "    dt: 'DecisionTreeClassifier',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00027-0fd37d79-9abc-44f7-8b88-1f91ace87dd6",
    "deepnote_cell_type": "code",
    "execution_millis": 2,
    "execution_start": 1608128622444,
    "output_cleared": false,
    "source_hash": "603e7071",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def roc_curve_plotter(model_dict, plot_top=False):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12,10))\n",
    "    axes = {}\n",
    "    for i, m in enumerate(model_dict.keys()):\n",
    "        axes[f'ax{i}'] = RocCurveDisplay.from_estimator(m, X_test, y_test, ax=ax, name=model_dict[m])\n",
    "    if plot_top:\n",
    "        for i, a in enumerate(axes):\n",
    "            if i != 0:\n",
    "                axes[a].line_.set_color('lightgrey')\n",
    "    plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--', label='Random Guess')\n",
    "    plt.title('ROC-AUC Curve Comparison', fontsize=22)\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00028-405890d8-9c5d-4d69-85d7-615cf3c39a02",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "We can confirm our initial analysis by looking at an AUC-ROC curve comparing all of our models. Our non-boosting tree classifiers tend to have a sharp drop off in true positive versus false positive rate after a specific threshold. In comparison, our Logistic Regression and Boosting models seem to be performing better in terms of AUC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00029-36110f57-d5c4-4342-b9ed-1ce298ca4e65",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "roc_curve_plotter(init_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00030-019d5a44-ebad-420b-9d8d-9b2fc2710f77",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "A reason for this could be that <b>our two classes aren't separated by a non-linear boundary</b>. As Decision Trees work by bisecting data into smaller and smaller regions, they tend to work pretty well in situations where there's a non linear boundary separating our data. Given that our classes don't seem to have any obvious \n",
    "pattern of non-linear separation throughout any of our features, \n",
    "our tree models are likely to overfit heavily. \n",
    "The simple linear boundary that Logistic Regression is most likely better in capturing the division between our classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00032-075376d3-fc8e-4353-a123-0e9549cfe7d6",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "To give an example of this, you can take a look at the below two graphs that demonstrate how a Decision Tree classifier could overfit when there's no clear separation between classes.\n",
    "We can see that Logistic Regression is a better tool for this particular job.\n",
    "<img src=\"/assets/boundaries.png\" alt=\"Decision Tree Non-Linear Boundary\" title=\"Decision Tree Overfitting due to Non-Linear Boundary\" width=\"800\" height=\"300\" />\n",
    "\n",
    "Source: [BigML](https://blog.bigml.com/2016/09/28/logistic-regression-versus-decision-trees/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00032-e2394383-f8a2-4b0d-8ba3-d06c9b667df0",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "As for our boosting algorithms, it seems likely that they're  performing well due to their ability to deal with imbalanced classes by constructing successive training sets based on incorrectly classified examples. \n",
    "\n",
    "In the next section, we'll try out hyperparameter tuning with all our models along with an oversampling techinque to address our class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00031-8b1f0e05-1356-4c64-bbfe-002156434619",
    "deepnote_cell_type": "markdown",
    "output_cleared": false
   },
   "source": [
    "## Hyperparameter Tuning with SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00032-7c933d83-cd93-4f61-949a-8ecc7e88a7b3",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "SMOTE is a commonly used oversampling method that attempts to balance class distribution by randomly increasing minority class examples by replicating them. In short, SMOTE synthesises new minority instances between existing minority instances. SMOTE works by selecting examples that are close in the feature space, drawing a line between the examples in the feature space and drawing a new sample at a point along that line. \n",
    "\n",
    "SMOTE is a pretty good choice here, given our imbalanced classes. Another option that we considered was <b>class weights</b>, where a heavier weightage is placed on the minority class and vice-versa for the majority class. However, we opted for SMOTE as some models like our Gradient Boosting classifier can't use class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00033-816fca3f-b00b-4cf7-8238-47b55ceb910f",
    "deepnote_cell_type": "code",
    "execution_millis": 26,
    "execution_start": 1608128623162,
    "output_cleared": false,
    "source_hash": "fee1599"
   },
   "outputs": [],
   "source": [
    "smt = SMOTE()\n",
    "X_train, y_train = smt.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00034-acfe72b2-8985-42e7-98bd-133e3a36df9d",
    "deepnote_cell_type": "markdown",
    "output_cleared": false
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00035-cac21cb8-4fdf-4b01-a757-4f5b80a882b9",
    "deepnote_cell_type": "code",
    "execution_millis": 1,
    "execution_start": 1608128623190,
    "output_cleared": false,
    "source_hash": "3e948428"
   },
   "outputs": [],
   "source": [
    "lr_params = {\n",
    "    # Trying different types of regularization\n",
    "    'lr__penalty':['l2','l1', 'elasticnet'],\n",
    "\n",
    "     # Trying different alphas of: 1, 0.1, 0.05  (C = 1/alpha)\n",
    "    'lr__C':[1, 10, 20],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00036-00347ffc-97e1-49e6-b921-a614257a110e",
    "deepnote_cell_type": "code",
    "execution_millis": 17669,
    "execution_start": 1608128623234,
    "output_cleared": false,
    "source_hash": "fb9d1e6b"
   },
   "outputs": [],
   "source": [
    "lr_gs = run_model('lr', mod_params=lr_params, grid_search=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00037-2749e59b-34b4-4f73-93fd-527d1fc4f0a0",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Saving for further analysis\n",
    "train_lr_gs = lr_gs\n",
    "train_preds = lr_gs.predict(X_test)\n",
    "train_probs = lr_gs.predict_proba(X_test)\n",
    "misclass_array = pd.DataFrame({'Actual': y_test, 'Predicted': train_preds}).to_numpy()\n",
    "misclass_probs = train_probs\n",
    "\n",
    "filename = './assets/train_gs_model.sav'\n",
    "pickle.dump(train_lr_gs, open(filename, 'wb'))\n",
    "\n",
    "filename = './assets/misclass_array.sav'\n",
    "pickle.dump(misclass_array, open(filename, 'wb'))\n",
    "\n",
    "filename = './assets/misclass_probs.sav'\n",
    "pickle.dump(misclass_probs, open(filename, 'wb'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00038-e5328e08-92b6-46d5-915e-1e5e63b9b794",
    "deepnote_cell_type": "markdown",
    "output_cleared": false
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00039-6d161b14-f28b-4746-abb8-396a5241d433",
    "deepnote_cell_type": "code",
    "execution_millis": 0,
    "execution_start": 1608128644011,
    "output_cleared": false,
    "source_hash": "31df1def"
   },
   "outputs": [],
   "source": [
    "dt_params = {'dt__max_depth': [20, 30],\n",
    "             'dt__min_samples_split': [5, 10, 15],\n",
    "             'dt__min_samples_leaf': [2, 3, 4],\n",
    "             'dt__class_weight': ['balanced']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00040-b027fd93-466f-4ded-b185-95ee542dfb66",
    "deepnote_cell_type": "code",
    "execution_millis": 16105,
    "execution_start": 1608128644348,
    "output_cleared": false,
    "source_hash": "3a417726"
   },
   "outputs": [],
   "source": [
    "dt_gs =  run_model('dt', mod_params=dt_params, grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00041-07ba7f83-acb9-4192-b787-f5663b7efa34",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "### Extra Trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00042-0489ec53-37ed-488e-bcbd-530842c56d85",
    "deepnote_cell_type": "code",
    "execution_millis": 2,
    "execution_start": 1608128660456,
    "output_cleared": false,
    "source_hash": "1fe72cc1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "et_params = {'et__n_estimators': [20, 25, 30],\n",
    "             'et__max_depth': [20, 30, 40],\n",
    "             'et__min_samples_leaf': [2, 3, 4],\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00043-79e126bc-3086-4534-84af-0d47abe6df3e",
    "deepnote_cell_type": "code",
    "execution_millis": 21572,
    "execution_start": 1608128758878,
    "output_cleared": false,
    "source_hash": "f13dd14b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "et_gs =  run_model('et', mod_params=et_params, grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00044-b1c2de9c-511e-44f6-b28a-5049d44d0a64",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00045-b2852150-a8e5-4273-b707-7a9b35bc8419",
    "deepnote_cell_type": "code",
    "execution_millis": 1,
    "execution_start": 1608128853566,
    "output_cleared": false,
    "source_hash": "74072e78",
    "tags": []
   },
   "outputs": [],
   "source": [
    "svc_params = {\n",
    "    'svc__C':[10, 30],\n",
    "    'svc__gamma':[0.01, 0.1], \n",
    "    'svc__kernel':['rbf', 'sigmoid'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00046-1074b71b-9017-43ee-9ca3-325a5f1a2c73",
    "deepnote_cell_type": "code",
    "execution_millis": 1895099,
    "execution_start": 1608128853726,
    "output_cleared": false,
    "source_hash": "4f360704",
    "tags": []
   },
   "outputs": [],
   "source": [
    "svc_gs =  run_model('svc', mod_params=svc_params, grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00047-e387c823-24f3-4b10-bd76-788e4ea8612a",
    "deepnote_cell_type": "markdown",
    "output_cleared": false
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00048-153c3751-b937-475e-9efe-3272e717f71e",
    "deepnote_cell_type": "code",
    "execution_millis": 2,
    "output_cleared": false,
    "source_hash": "818ae80f"
   },
   "outputs": [],
   "source": [
    "rf_params = {'rf__n_estimators': [20, 25, 30],\n",
    "             'rf__max_depth': [20, 30, 40],\n",
    "             'rf__min_samples_leaf': [2, 3, 4],\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00049-f8899325-0bf6-48ff-8de3-14a8e474a66d",
    "deepnote_cell_type": "code",
    "execution_millis": 48356,
    "output_cleared": false,
    "source_hash": "b2289f2a"
   },
   "outputs": [],
   "source": [
    "rf_gs =  run_model('rf', mod_params=rf_params, grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00050-a0445189-7d2d-4431-96fa-20e6147b2da5",
    "deepnote_cell_type": "markdown",
    "output_cleared": false
   },
   "source": [
    "### Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00051-2b9d38d8-36cc-4432-908a-a672e2fd1a3b",
    "deepnote_cell_type": "code",
    "execution_millis": 1,
    "output_cleared": false,
    "source_hash": "605ca1e4"
   },
   "outputs": [],
   "source": [
    "ada_params = {'ada__n_estimators': [500, 1000],\n",
    "              'ada__learning_rate': [0.9, 1.0],\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00052-00963070-2a52-4a6b-8861-9f265cae8d4a",
    "deepnote_cell_type": "code",
    "execution_millis": 147596,
    "output_cleared": false,
    "source_hash": "3043ad5b"
   },
   "outputs": [],
   "source": [
    "ada_gs = run_model('ada', mod_params=ada_params, grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00053-59769990-73ce-4a7e-b426-b844f3519332",
    "deepnote_cell_type": "markdown",
    "output_cleared": false
   },
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00054-59a272ab-9194-4dc6-b774-9163715b25c8",
    "deepnote_cell_type": "code",
    "execution_millis": 1,
    "output_cleared": false,
    "source_hash": "d4dc6cc7"
   },
   "outputs": [],
   "source": [
    "gb_params = {'gb__n_estimators': [500, 1000],\n",
    "             'gb__learning_rate': [0.4, 0.5, 0.6],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00055-5ff7ba13-4cdf-4ccf-88c6-194f5f4e2af5",
    "deepnote_cell_type": "code",
    "execution_millis": 397867,
    "output_cleared": false,
    "source_hash": "f23e8be3"
   },
   "outputs": [],
   "source": [
    "gb_gs = run_model('gb', mod_params=gb_params, grid_search=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics result after Hyperparameter Tuning with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00056-6e98fdee-308e-4356-92fb-506363492b9a",
    "deepnote_cell_type": "code",
    "execution_millis": 13,
    "output_cleared": false,
    "source_hash": "a3600245"
   },
   "outputs": [],
   "source": [
    "gs_df = pd.DataFrame(gs_list)\n",
    "gs_df.sort_values(by='test_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning does help to improve roc-auc score of some classifiers, but not so much for logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00057-456ef7e8-1ef4-4f80-9aa7-c6809175d17a",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "### Final AUC-ROC Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00058-cee770dd-ec5d-4f21-a720-d318ad6a55e7",
    "deepnote_cell_type": "code",
    "execution_millis": 0,
    "output_cleared": false,
    "source_hash": "25a34212",
    "tags": []
   },
   "outputs": [],
   "source": [
    "gs_dict = {\n",
    "    lr_gs: 'LogisticRegression',\n",
    "    gb_gs: 'GradientBoostingClassifier',\n",
    "    ada_gs: 'AdaBoostClassifier',\n",
    "    rf_gs: 'RandomForest',\n",
    "    svc_gs: 'SupportVectorMachineClf',\n",
    "    # et_gs: 'ExtraTreeClassifier',\n",
    "    dt_gs: 'DecisionTreeClassifier',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00059-62fa2d74-9030-4779-af91-439ff458f9ee",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Our Logistic Regression model seems not to be a better winner here in terms of AUC score. Looking at the curve, we see that it outperforms some models at most classification thresholds. SMOTE also seems to have helped most of our models improve their AUC score. Though it seems that Random Forest and Extra Tree Classifier are doing better while our Support Vector Machine classifier and Decision Tree Classifier are doing pretty badly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00060-c5c1eeba-233f-44e1-8857-33b904d62e5e",
    "deepnote_cell_type": "code",
    "execution_millis": 1217,
    "output_cleared": false,
    "source_hash": "d75b0b5d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "roc_curve_plotter(gs_dict, plot_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00061-ca1d1adc-4975-46a5-a49e-e7d3e073b37a",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Precision-Recall AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00062-6f77c5ab-9ae5-4fa2-959a-192e0980cca7",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Beyond focusing just on AUC which looks how good our modelling is at separating our positive and negative class, we also want to pay close attention to our model's ability to classify most or all of our minority class (which in this case is our positive class). Using a Precision-Recall AUC curve, we can look at the trade-off between precision (number out of true positives out of all predicted positives) and recall (number of true positives out of all predicted results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00063-e0895651-24b4-485a-bb7e-875bff996523",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "def plot_pr_curve(model, model_dict):\n",
    "    # Predict probabilities\n",
    "    probs = model.predict_proba(X_test)\n",
    "    # Keep probabilities for the positive outcome only\n",
    "    probs = probs[:, 1]\n",
    "    # Predict class values\n",
    "    yhat = model.predict(X_test)\n",
    "    # Calculate precision-recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_test, yhat)\n",
    "    # Calculate precision-recall AUC\n",
    "    auc_score = auc(recall, precision)\n",
    "    # Calculate average precision score\n",
    "    ap = average_precision_score(y_test, probs)\n",
    "    print(f'{model_dict[model]}: f1=%.3f pr-auc=%.3f avg. prec=%.3f' % (f1, auc_score, ap))\n",
    "    # Plot the ROC curve for the model\n",
    "    plt.plot(recall, precision, marker='.', label=model_dict[model])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00064-6202d4db-e000-4d88-96e3-95d4a03dafb1",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "We can see that at most thresholds, our logistic regression model is able to outperform the other two models in terms of recall. This means that our logistic regression model is doing comparatively well in classifying our positive class. Given that we believe recall to be more important than precision here (ignoring WNV could lead to human death), our logistic regession model seems like a solid choice. If precision was more important for us, we could opt for a gradient boosting classifier instead as it seems to be better at maximising precision over recall at earlier parts of the curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00065-2de70622-8288-4cdb-ac1a-7fa4f3b72a0c",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plot_pr_curve(lr_gs, gs_dict)\n",
    "plot_pr_curve(dt_gs, gs_dict)\n",
    "plot_pr_curve(gb_gs, gs_dict)\n",
    "plt.plot([0, 1], [0.05, 0.05], linestyle='--', color = 'black', label='Random Guessing')\n",
    "plt.title('Precision-Recall Curve', fontsize=18)\n",
    "plt.legend(fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00066-945cf085-572f-40b5-966b-d7dda296d411",
    "deepnote_cell_type": "markdown",
    "output_cleared": false
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00067-4775e8c8-a78e-489d-9de7-8e91b35d5d85",
    "deepnote_cell_type": "code",
    "execution_millis": 4,
    "output_cleared": false,
    "source_hash": "323f35cc"
   },
   "outputs": [],
   "source": [
    "feat_imp = pd.DataFrame(gb_gs.best_estimator_.steps[1][1].feature_importances_, index=X_train.columns, columns=['Importance']).sort_values('Importance', ascending=False)\n",
    "feat_imp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00068-1adfdab1-7a86-47bb-85e6-386e2af4e9bd",
    "deepnote_cell_type": "code",
    "execution_millis": 176041,
    "output_cleared": false,
    "source_hash": "f5e0fb7e"
   },
   "outputs": [],
   "source": [
    "# Refit model on training data\n",
    "final_model = lr_gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00069-7e962584-6b2b-48d3-a452-633351b2bf4c",
    "deepnote_cell_type": "code",
    "execution_millis": 2109,
    "output_cleared": false,
    "source_hash": "b5267a7a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_gs_df = pd.DataFrame(columns=X.columns, data=lr_gs.best_estimator_.steps[1][1].coef_).T\n",
    "lr_gs_df.columns = ['coefs']\n",
    "lr_gs_df = lr_gs_df.sort_values(ascending=False, by='coefs')\n",
    "plt.figure(figsize=(10, 12))\n",
    "sns.barplot(data=lr_gs_df, y=lr_gs_df.index, x='coefs', orient='h')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fname='./assets/final_model', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00070-959c38d6-e17e-4a69-97f1-72b0a3ee67eb",
    "deepnote_cell_type": "code",
    "execution_millis": 54,
    "output_cleared": false,
    "source_hash": "17b3450b"
   },
   "outputs": [],
   "source": [
    "predictions = final_model.predict(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00071-ab45a0a0-bd10-4380-9957-e50416f5c54d",
    "deepnote_cell_type": "code",
    "execution_millis": 2,
    "output_cleared": false,
    "source_hash": "cdcf9567"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predictions)\n",
    "df[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00072-0fc37dc9-b48e-4e9e-9348-09d105313f4d",
    "deepnote_cell_type": "code",
    "execution_millis": 86,
    "output_cleared": false,
    "source_hash": "7034649"
   },
   "outputs": [],
   "source": [
    "pred_proba = final_model.predict_proba(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00073-83485486-05e5-4cf0-bfd4-08e4d0405d85",
    "deepnote_cell_type": "code",
    "execution_millis": 108,
    "output_cleared": false,
    "source_hash": "a27ebf02"
   },
   "outputs": [],
   "source": [
    "pred_proba_t = [i[1] for i in pred_proba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00074-31b9f1ac-b54a-4732-b599-af2547347e18",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Saving final model for further analysis\n",
    "filename = './assets/final_model.sav'\n",
    "pickle.dump(final_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00075-64dbde4a-2628-4a9a-b246-3ab4913a5c7a",
    "deepnote_cell_type": "markdown",
    "output_cleared": false
   },
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00076-5c83bfbf-700b-4426-a00b-69b25c3a49d9",
    "deepnote_cell_type": "code",
    "execution_millis": 55,
    "output_cleared": false,
    "source_hash": "cfc650ac",
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test_id\n",
    "submission['WnvPresent'] = pred_proba_t\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00077-956e865a-89ab-42aa-a59a-3f2e06265f01",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Manual Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00078-e34ca2ee-d65a-4617-a01c-e5941313bf59",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "test['Date'] = pd.to_datetime(test['Date'])\n",
    "test['Year'] = test['Date'].apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00079-d83c63a0-a829-4105-975d-503629b4b2f1",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "submission['Year'] = test['Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00080-6b1c579b-523b-46e2-bf27-59891fd81b4b",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "def year_mod(row):\n",
    "    if row['Year'] == 2012:\n",
    "        row['WnvPresent'] = row['WnvPresent'] * 2\n",
    "        if row['WnvPresent'] > 1:\n",
    "            row['WnvPresent'] = 0.99\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00081-52227c7c-0069-4c57-9c88-965321979c8a",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "submission = submission.apply(year_mod, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00082-967ad398-f8fb-41ba-b43d-642e6f7ecee0",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "submission['Id'] = submission['Id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00083-4d482865-ef70-47e6-83e9-0de49ba8da79",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "submission = submission.drop(columns='Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00076-5c83bfbf-700b-4426-a00b-69b25c3a49d9",
    "deepnote_cell_type": "code",
    "execution_millis": 55,
    "output_cleared": false,
    "source_hash": "cfc650ac",
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_01 = submission.copy()\n",
    "submission_01['WnvPresent'] = [i for i in predictions]\n",
    "submission_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00084-4ecb0bbc-5f55-46e6-95ff-0a99c031118b",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "#### Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00085-b2d5fbec-51d0-47b5-8c69-29d8de93458b",
    "deepnote_cell_type": "code",
    "execution_millis": 406,
    "output_cleared": false,
    "source_hash": "16066387"
   },
   "outputs": [],
   "source": [
    "submission.to_csv('./datasets/kaggle.csv', index=False)\n",
    "submission_01.to_csv('./datasets/kaggle_01.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "2d7648bc-ca60-4f70-922c-bee257b0fbad",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "81a971b6fd9cff190434588cdf172cac48714af52f7090df243948b872fd6cd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
